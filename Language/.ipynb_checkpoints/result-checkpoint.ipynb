{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 3000 1000 H\n",
      "1000 0 1000 e\n",
      "0 1000 1000 l\n",
      "0 1000 1000 l\n",
      "3000 0 1000 o\n",
      "0 0 1000  \n",
      "1000 0 1000 m\n",
      "3000 0 1000 y\n",
      "0 0 1000  \n",
      "3000 0 1000 n\n",
      "0 1000 1000 a\n",
      "1000 0 1000 m\n",
      "1000 0 1000 e\n",
      "0 0 1000  \n",
      "0 1000 1000 i\n",
      "0 3000 1000 s\n",
      "0 0 1000  \n",
      "0 1000 1000 A\n",
      "0 3000 1000 h\n",
      "1000 0 1000 m\n",
      "1000 0 1000 e\n",
      "3000 0 1000 d\n",
      "0 0 1000  \n",
      "1000 0 1000 E\n",
      "0 1000 1000 l\n",
      "1000 0 1000 m\n",
      "0 1000 1000 a\n",
      "0 1000 1000 l\n",
      "0 1000 1000 a\n",
      "0 3000 1000 w\n",
      "0 1000 1000 a\n",
      "3000 0 1000 n\n",
      "3000 0 1000 y\n",
      "0 0 0 \n",
      "\n",
      "3000 0 1000 N\n",
      "0 1000 1000 i\n",
      "0 1000 1000 c\n",
      "1000 0 1000 e\n",
      "0 0 1000  \n",
      "1000 0 1000 t\n",
      "3000 0 1000 o\n",
      "0 0 1000  \n",
      "1000 0 1000 m\n",
      "1000 0 1000 e\n",
      "1000 0 1000 e\n",
      "1000 0 1000 t\n",
      "0 0 1000  \n",
      "3000 0 1000 y\n",
      "3000 0 1000 o\n",
      "1000 0 1000 u\n"
     ]
    }
   ],
   "source": [
    "!python vibration_language_system.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting azure-cognitiveservices-speech\n",
      "  Using cached azure_cognitiveservices_speech-1.15.0-cp36-cp36m-win_amd64.whl (1.6 MB)\n",
      "Installing collected packages: azure-cognitiveservices-speech\n",
      "Successfully installed azure-cognitiveservices-speech-1.15.0\n"
     ]
    }
   ],
   "source": [
    "!pip install azure-cognitiveservices-speech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import azure.cognitiveservices.speech as speechsdk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "speech_config = speechsdk.SpeechConfig(subscription=\"<a84d979ee7254fc181e808c7e84372c6>\", region=\"<canadacentral>\")\n",
    "audio_config = speechsdk.audio.AudioConfig(device_name=\"<Realtek(R) Audio>\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Exception with an error code: 0xe (SPXERR_MIC_NOT_AVAILABLE)\n[CALL STACK BEGIN]\n\n    > user_get_id\n\n    - user_get_id\n\n    - user_get_id\n\n    - user_get_id\n\n    - user_get_id\n\n    - user_get_id\n\n    - user_get_id\n\n    - user_get_id\n\n    - user_get_id\n\n    - user_get_id\n\n    - user_get_id\n\n    - user_get_id\n\n    - user_get_id\n\n    - user_get_id\n\n    - user_get_id\n\n    - user_get_id\n\n\n\n[CALL STACK END]\n\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-7687dbc7748a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     16\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Error details: {}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcancellation_details\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merror_details\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m \u001b[0mfrom_mic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mspeech_config\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-18-7687dbc7748a>\u001b[0m in \u001b[0;36mfrom_mic\u001b[1;34m(speech_config)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mfrom_mic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mspeech_config\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0mspeech_recognizer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mspeechsdk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSpeechRecognizer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mspeech_config\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mspeech_config\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maudio_config\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maudio_config\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Speak into your microphone.\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mspeech_recognizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecognize_once_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\enel400\\lib\\site-packages\\azure\\cognitiveservices\\speech\\speech.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, speech_config, audio_config, language, source_language_config, auto_detect_source_language_config)\u001b[0m\n\u001b[0;32m    800\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    801\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 802\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_impl\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimpl\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSpeechRecognizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mspeech_config\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maudio_config\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlanguage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msource_language_config\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mauto_detect_source_language_config\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    803\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    804\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mrecognize_once\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mSpeechRecognitionResult\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\enel400\\lib\\site-packages\\azure\\cognitiveservices\\speech\\speech.py\u001b[0m in \u001b[0;36m_get_impl\u001b[1;34m(reco_type, speech_config, audio_config, language, source_language_config, auto_detect_source_language_config)\u001b[0m\n\u001b[0;32m    863\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0maudio_config\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    864\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mreco_type\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_from_config\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mspeech_config\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_impl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 865\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mreco_type\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_from_config\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mspeech_config\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_impl\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[0maudio_config\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_impl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    866\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlanguage\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    867\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0maudio_config\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Exception with an error code: 0xe (SPXERR_MIC_NOT_AVAILABLE)\n[CALL STACK BEGIN]\n\n    > user_get_id\n\n    - user_get_id\n\n    - user_get_id\n\n    - user_get_id\n\n    - user_get_id\n\n    - user_get_id\n\n    - user_get_id\n\n    - user_get_id\n\n    - user_get_id\n\n    - user_get_id\n\n    - user_get_id\n\n    - user_get_id\n\n    - user_get_id\n\n    - user_get_id\n\n    - user_get_id\n\n    - user_get_id\n\n\n\n[CALL STACK END]\n\n"
     ]
    }
   ],
   "source": [
    "def from_mic(speech_config):\n",
    "    speech_recognizer = speechsdk.SpeechRecognizer(speech_config=speech_config, audio_config=audio_config)\n",
    "    \n",
    "    print(\"Speak into your microphone.\")\n",
    "    result = speech_recognizer.recognize_once_async().get()\n",
    "    print(result.text)\n",
    "    \n",
    "    if result.reason == speechsdk.ResultReason.RecognizedSpeech:\n",
    "        print(\"Recognized: {}\".format(result.text))\n",
    "    elif result.reason == speechsdk.ResultReason.NoMatch:\n",
    "        print(\"No speech could be recognized: {}\".format(result.no_match_details))\n",
    "    elif result.reason == speechsdk.ResultReason.Canceled:\n",
    "        cancellation_details = result.cancellation_details\n",
    "        print(\"Speech Recognition canceled: {}\".format(cancellation_details.reason))\n",
    "        if cancellation_details.reason == speechsdk.CancellationReason.Error:\n",
    "            print(\"Error details: {}\".format(cancellation_details.error_details))\n",
    "\n",
    "from_mic(speech_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Say now!!!!\n",
      "Ahmed\n"
     ]
    }
   ],
   "source": [
    "!python vibration_language_system.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting SpeechRecognition\n",
      "  Downloading SpeechRecognition-3.8.1-py2.py3-none-any.whl (32.8 MB)\n",
      "Installing collected packages: SpeechRecognition\n",
      "Successfully installed SpeechRecognition-3.8.1\n",
      "Collecting pyaudio\n",
      "  Downloading PyAudio-0.2.11-cp36-cp36m-win_amd64.whl (52 kB)\n",
      "Installing collected packages: pyaudio\n",
      "Successfully installed pyaudio-0.2.11\n"
     ]
    }
   ],
   "source": [
    "!pip install SpeechRecognition\n",
    "!pip install pyaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Microsoft Sound Mapper - Input', 'Microphone (Realtek(R) Audio)', 'Microsoft Sound Mapper - Output', 'Speakers/Headphones (Realtek(R)']\n"
     ]
    }
   ],
   "source": [
    "import speech_recognition as s_r\n",
    "print(s_r.Microphone.list_microphone_names()) #print all the microphones connected to your machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Say now!!!!\n",
      "hello\n",
      "test\n",
      "1000 0 1000 t\n",
      "1000 0 1000 e\n",
      "0 3000 1000 s\n",
      "1000 0 1000 t\n"
     ]
    }
   ],
   "source": [
    "r = s_r.Recognizer()\n",
    "my_mic = s_r.Microphone(device_index=1) #my device index is 1, you have to put your device index\n",
    "with my_mic as source:\n",
    "    print(\"Say now!!!!\")\n",
    "    r.adjust_for_ambient_noise(source) #reduce noise\n",
    "    audio = r.listen(source) #take voice input from the microphone\n",
    "test = r.recognize_google(audio)\n",
    "print(test) #to print voice into text\n",
    "!python vibration_language_system.py -t test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python vibration_language_system.py"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python_3.6",
   "language": "python",
   "name": "python_3.6"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
